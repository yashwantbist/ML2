{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = \"car_price_dataset.csv\"\n",
    "df = pd.read_csv(\"./car_price_dataset.csv\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "numerical_columns = [ 'Year', 'Engine_Size',   'Mileage', 'Doors', 'Owner_Count', 'Price']\n",
    "df_num = df[numerical_columns]\n",
    "\n",
    "# Features (drop target column)\n",
    "X_train = df_num.drop('Year', axis=1)  \n",
    "# Target variable (Brand)\n",
    "y_train = df_num['Year']  \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#An R-squared (RÂ²) value of 0.9676 means that your Random Forest Regressor explains 96.76% of the variance in the target variable ('Mileage') based on the input features. we checked with apple stock also so it gave high r2 value\n",
    "#so we changed it to another dataset of car, it came to 96% which means  that the model has captured the relationship between features and the target variable well.\n",
    "\n",
    "r2 = rf.score(X_train, y_train)\n",
    "print(f\"R-squared: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
